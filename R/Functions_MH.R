# Function Parses a VCF file generated by freebayes filtering process
# Function Parses a VCF file generated by freebayes filtering process
#' @title QTLParser_1_MH
#' @description Parses a vcf file which has been converted to a tidy data frame before running the operation
#' @param vcf A vcf file that is as a tidy data frame
#' @param HighBulk The name of the HighBulk sample
#' @param LowBulk The name of the LowBulk sample
#' @export

QTLParser_1_MH <- function(vcf,HighBulk,LowBulk){
  #vcf is a vcf file converted to a tidy data frame
  CHROM <- vcf$fix$ChromKey
  POS <- vcf$fix$POS
  REF <- vcf$fix$REF
  ALT <- vcf$fix$ALT
  DP <- VCF_TIDY$gt$gt_DP
  Samples <- vcf$gt$Indiv
  AD <- vcf$gt$gt_AD
  Data <- data.frame(AD,Samples)
  var1 <- AD[(as.matrix(Data[2]==HighBulk))]
  Data <- data.frame(CHROM,POS,REF,ALT,DP,var1,Samples)
  Data <- Data %>% drop_na(var1)
  str(Data)
  var2 <- Data$var1
  var <- unlist(strsplit(var2,","))
  len <- length(var)
  seq <- seq(1,len,2)
  AD_REF. <- var[c(seq)]
  seq2 <- seq(2,len,2)
  AD_ALT. <- var[c(seq2)]
  Data$AD_REF. <- AD_REF.
  Data$AD_ALT. <- AD_ALT.
  Data<-Data[,-6]
  Data<-Data[!rowSums(nchar(as.matrix(Data[3]))!=1),]
  Data<-Data[!rowSums(nchar(as.matrix(Data[4]))!=1),]
  Data<-Data <- Data[(as.matrix(Data[6])==HighBulk),]
  Data<-Data[,-6]
  #Data<-Data[,-5]
  write.table(Data, file = paste0(HighBulk,".tsv"),row.names = FALSE,col.names = TRUE,sep="\t",quote = FALSE)
  write.table(Data, file = paste0(HighBulk,".csv"),row.names = FALSE,col.names = TRUE,sep=",",quote = FALSE)
  CHROM <- vcf$fix$ChromKey
  POS <- vcf$fix$POS
  REF <- vcf$fix$REF
  ALT <- vcf$fix$ALT
  DP <- VCF_TIDY$gt$gt_DP
  Samples <- vcf$gt$Indiv
  AD <- vcf$gt$gt_AD
  Data <- data.frame(AD,Samples)
  var1 <- AD[(as.matrix(Data[2]==LowBulk))]
  Data <- data.frame(CHROM,POS,REF,ALT,DP,var1,Samples)
  Data <- Data %>% drop_na(var1)
  str(Data)
  var2 <- Data$var1
  var <- unlist(strsplit(var2,","))
  len <- length(var)
  seq <- seq(1,len,2)
  AD_REF. <- var[c(seq)]
  seq2 <- seq(2,len,2)
  AD_ALT. <- var[c(seq2)]
  Data$AD_REF. <- AD_REF.
  Data$AD_ALT. <- AD_ALT.
  Data<-Data[,-6]
  Data<-Data[!rowSums(nchar(as.matrix(Data[3]))!=1),]
  Data<-Data[!rowSums(nchar(as.matrix(Data[4]))!=1),]
  Data<-Data <- Data[(as.matrix(Data[6])==LowBulk),]
  Data<-Data[,-6]
  #Data<-Data[,-5]
  write.table(Data, file = paste0(LowBulk,".tsv"),row.names = FALSE,col.names = TRUE,sep="\t",quote = FALSE)
  write.table(Data, file = paste0(LowBulk,".csv"),row.names = FALSE,col.names = TRUE,sep=",",quote = FALSE)


  df1 <- read.csv(file = paste0(HighBulk,".csv"),header = TRUE)
  df2 <- read.csv(file = paste0(LowBulk,".csv"), header = TRUE)
  df3 <- merge(df1,df2,by=c("CHROM","POS","REF","ALT"),all.x = TRUE)


  names(df3)[5] <- paste0("DP.",HighBulk)
  names(df3)[6] <- paste0("AD_REF.",HighBulk)
  names(df3)[7] <- paste0("AD_ALT.",HighBulk)
  names(df3)[8] <- paste0("DP.",LowBulk)
  names(df3)[9] <- paste0("AD_REF.",LowBulk)


  names(df3)[5] <- paste0("DP.",HighBulk)
  names(df3)[6] <- paste0("AD_REF.",HighBulk)
  names(df3)[7] <- paste0("AD_ALT.",HighBulk)
  names(df3)[8] <- paste0("DP.",LowBulk)
  names(df3)[9] <- paste0("AD_REF.",LowBulk)

  names(df3)[10] <- paste0("AD_ALT.",LowBulk)
  write.table(df3, file = "Hall.csv",row.names = FALSE,col.names = TRUE,sep = ",")

}

# Function Parses a VCF file generated by freebayes filtering process
# Function Parses a VCF file generated by freebayes filtering process
#' @title QTLParser_2_MH
#' @description Parses a vcf file which has been converted to a tidy data frame before running the operation
#' @param vcf A vcf file that is as a tidy data frame
#' @param HighBulk The name of the HighBulk sample
#' @param LowBulk The name of the LowBulk sample
#' @param RootDirectory The name of the Root Directory
#' @export
QTLParser_2_MH <- function(vcf,HighBulk,LowBulk,RootDirectory){
  #vcf is a vcf file converted to a tidy data frame
  CHROM <- vcf$fix$ChromKey
  POS <- vcf$fix$POS
  REF <- vcf$fix$REF
  ALT <- vcf$fix$ALT
  DP <- VCF_TIDY$gt$gt_DP
  Samples <- vcf$gt$Indiv
  AD <- vcf$gt$gt_AD
  Data <- data.frame(AD,Samples)
  var1 <- AD[(as.matrix(Data[2]==HighBulk))]
  Data <- data.frame(CHROM,POS,REF,ALT,DP,var1,Samples)
  Data <- Data %>% drop_na(var1)
  str(Data)
  var2 <- Data$var1
  var <- unlist(strsplit(var2,","))
  len <- length(var)
  seq <- seq(1,len,2)
  AD_REF. <- var[c(seq)]
  seq2 <- seq(2,len,2)
  AD_ALT. <- var[c(seq2)]
  Data$AD_REF. <- AD_REF.
  Data$AD_ALT. <- AD_ALT.
  Data<-Data[,-6]
  Data<-Data[!rowSums(nchar(as.matrix(Data[3]))!=1),]
  Data<-Data[!rowSums(nchar(as.matrix(Data[4]))!=1),]
  Data<-Data <- Data[(as.matrix(Data[6])==HighBulk),]
  Data<-Data[,-6]
  #Data<-Data[,-5]
  RootDirectory <- RootDirectory
  setwd(paste0("/home/michael/Desktop/",RootDirectory,"/QTLParser_CSV/"))
  write.table(Data, file = paste0(HighBulk,".tsv"),row.names = FALSE,col.names = TRUE,sep="\t",quote = FALSE)
  write.table(Data, file = paste0(HighBulk,".csv"),row.names = FALSE,col.names = TRUE,sep=",",quote = FALSE)
  setwd(paste0("/home/michael/Desktop/",RootDirectory))
  CHROM <- vcf$fix$ChromKey
  POS <- vcf$fix$POS
  REF <- vcf$fix$REF
  ALT <- vcf$fix$ALT
  DP <- VCF_TIDY$gt$gt_DP
  Samples <- vcf$gt$Indiv
  AD <- vcf$gt$gt_AD
  Data <- data.frame(AD,Samples)
  var1 <- AD[(as.matrix(Data[2]==LowBulk))]
  Data <- data.frame(CHROM,POS,REF,ALT,DP,var1,Samples)
  Data <- Data %>% drop_na(var1)
  str(Data)
  var2 <- Data$var1
  var <- unlist(strsplit(var2,","))
  len <- length(var)
  seq <- seq(1,len,2)
  AD_REF. <- var[c(seq)]
  seq2 <- seq(2,len,2)
  AD_ALT. <- var[c(seq2)]
  Data$AD_REF. <- AD_REF.
  Data$AD_ALT. <- AD_ALT.
  Data<-Data[,-6]
  Data<-Data[!rowSums(nchar(as.matrix(Data[3]))!=1),]
  Data<-Data[!rowSums(nchar(as.matrix(Data[4]))!=1),]
  Data<-Data <- Data[(as.matrix(Data[6])==LowBulk),]
  Data<-Data[,-6]
  #Data<-Data[,-5]
  setwd(paste0("/home/michael/Desktop/",RootDirectory,"/QTLParser_CSV/"))
  write.table(Data, file = paste0(LowBulk,".tsv"),row.names = FALSE,col.names = TRUE,sep="\t",quote = FALSE)
  write.table(Data, file = paste0(LowBulk,".csv"),row.names = FALSE,col.names = TRUE,sep=",",quote = FALSE)
  
  
  df1 <- read.csv(file = paste0(HighBulk,".csv"),header = TRUE)
  df2 <- read.csv(file = paste0(LowBulk,".csv"), header = TRUE)
  df3 <- merge(df1,df2,by=c("CHROM","POS","REF","ALT"),all.x = TRUE)
  
  
  names(df3)[5] <- paste0("DP.",HighBulk)
  names(df3)[6] <- paste0("AD_REF.",HighBulk)
  names(df3)[7] <- paste0("AD_ALT.",HighBulk)
  names(df3)[8] <- paste0("DP.",LowBulk)
  names(df3)[9] <- paste0("AD_REF.",LowBulk)
  
  
  names(df3)[5] <- paste0("DP.",HighBulk)
  names(df3)[6] <- paste0("AD_REF.",HighBulk)
  names(df3)[7] <- paste0("AD_ALT.",HighBulk)
  names(df3)[8] <- paste0("DP.",LowBulk)
  names(df3)[9] <- paste0("AD_REF.",LowBulk)
  
  names(df3)[10] <- paste0("AD_ALT.",LowBulk)
  write.table(df3, file = "Hall.csv",row.names = FALSE,col.names = TRUE,sep = ",")
  
}

#' @title runGprimeAnalysis_MH
#' @description Runs a Gprime Analysis on Bulk segregants 
#' @param SNPset An SNPset
#' @param windowSize Specify the WindowSize
#' @param outlierFilter Specify the outlierFilter 
#' @param filterThreshold Specify threshold filter value default is 0.1
#' @export

runGprimeAnalysis_MH <-
  function (SNPset, windowSize = 1e+06, outlierFilter = "deltaSNP",
            filterThreshold = 0.1, ...)
  {
    message("Counting SNPs in each window...")
    SNPset <- SNPset %>% dplyr::group_by(CHROM) %>% dplyr::mutate(nSNPs = countSNPs_cpp(POS = POS,
                                                                                        windowSize = windowSize))
    message("Calculating tricube smoothed delta SNP index...")
    SNPset <- SNPset %>% dplyr::mutate(tricubeDeltaSNP = tricubeStat(POS = POS,
                                                                     Stat = deltaSNP, windowSize))
    message("Calculating G and G' statistics...")
    SNPset <- SNPset %>% dplyr::mutate(G = getG_MH(LowRef = AD_REF.LOW,
                                                   HighRef = AD_REF.HIGH, LowAlt = AD_ALT.LOW, HighAlt = AD_ALT.HIGH),
                                       Gprime = tricubeStat_MH(POS = POS, Stat = G, windowSize = windowSize,
                                                               ...)) %>% dplyr::ungroup() %>% dplyr::mutate(pvalue = getPvals_MH(Gprime = Gprime,
                                                                                                                                 deltaSNP = deltaSNP, outlierFilter = outlierFilter, filterThreshold = filterThreshold),
                                                                                                            negLog10Pval = -log10(pvalue), qvalue = p.adjust(p = pvalue,
                                                                                                                                                             method = "BH"))
    return(as.data.frame(SNPset))
  }


#' @title runGprimeAnalysis_GPrime_Smooth
#' @description Runs a Gprime Analysis on Bulk segregants with additional smoothing parameters for G Prime Test Statistic
#' @param SNPset An SNPset
#' @param windowSize Specify the WindowSize
#' @param outlierFilter Specify the outlierFilter 
#' @param filterThreshold Specify threshold filter value default is 0.1
#' @param deg Degree of Polynomial to use for LocFit Model
#' @param nn Nearest Neighbor component of smoothing parameter. Default value is 0.7, unless h or adpen are provided, in which case the default is 0
#' @export


runGprimeAnalysis_GPrime_Smooth <- 
  function (SNPset, windowSize = windowSize, outlierFilter = "deltaSNP", 
            filterThreshold = 0.1, deg = deg, nn = nn) 
  {
    message("Counting SNPs in each window...")
    SNPset <- SNPset %>% dplyr::group_by(CHROM) %>% dplyr::mutate(nSNPs = countSNPs_cpp(POS = POS, windowSize = windowSize))
    message("Calculating tricube smoothed delta SNP index...")
    SNPset <- SNPset %>% dplyr::mutate(tricubeDeltaSNP = tricubeStat_MH(POS = POS, Stat = deltaSNP, windowSize))
    message("Calculating G and G' statistics...")
    SNPset <- SNPset %>% dplyr::mutate(G = getG_MH(LowRef = AD_REF.LOW, HighRef = AD_REF.HIGH, LowAlt = AD_ALT.LOW, HighAlt = AD_ALT.HIGH), Gprime = tricube_Smooth(POS = POS, Stat = G, windowSize = windowSize, deg = deg, nn = nn, h = h)) %>% dplyr::ungroup() %>% dplyr::mutate(pvalue = getPvals_MH(Gprime = Gprime, deltaSNP = deltaSNP, outlierFilter = outlierFilter, filterThreshold = filterThreshold), negLog10Pval = -log10(pvalue), qvalue = p.adjust(p = pvalue, method = "BH"))
    return(as.data.frame(SNPset))
  }
#' @title tricube_Smooth
#' @description Applies Tricube Kernel to G Test Statistic
#' @param POS THe Position vector of where the SNPs were called
#' @param Stat The G Statistic, however, it is the G~lp(x) for a local regression and likelihood model
#' @param windowSize Specify the WindowSize
#' @param deg Degree of Polynomial to use for LocFit Model 
#' @param nn Nearest Neighbor component of smoothing parameter. Default value is 0.7, unless h or adpen are provided, in which case the default is 0
#' @export




tricube_Smooth <- 
  function (POS, Stat, windowSize, deg, nn, h) 
  {
    if (windowSize <= 0) 
      stop("A positive smoothing window is required")
    stats::predict(locfit::locfit(Stat ~ locfit::lp(POS, h = windowSize, 
                                                    deg = deg, nn = nn)), POS)
  }



#' @title tricubeStat_MH
#' @description Delivers a tricubeStat function 
#' @param POS An SNPset
#' @param Stat Specify the WindowSize
#' @param windowSize Specify the outlierFilter 
#' @export
tricubeStat_MH <- function(POS, Stat, windowSize = 2e6, ...)
{
  if (windowSize <= 0)
    stop("A positive smoothing window is required")
  stats::predict(locfit::locfit(Stat ~ locfit::lp(POS, h = windowSize, deg = 0), ...), POS)
}


#' @title getG_MH
#' @description Calculates/Returns a G Statistics 
#' @param LowRef LowReference Allele 
#' @param HighRef HighReference Allele
#' @param LowAlt LowAlternate Allele 
#' @param HighAlt HighAlternate Allele
#' @export 
getG_MH <- function(LowRef, HighRef, LowAlt, HighAlt)
{
  exp <- c(
    (LowRef + HighRef) * (LowRef + LowAlt) / (LowRef + HighRef + LowAlt + HighAlt),
    (LowRef + HighRef) * (HighRef + HighAlt) / (LowRef + HighRef + LowAlt + HighAlt),
    (LowRef + LowAlt) * (LowAlt + HighAlt) / (LowRef + HighRef + LowAlt + HighAlt),
    (LowAlt + HighAlt) * (HighRef + HighAlt) / (LowRef + HighRef + LowAlt + HighAlt)
  )
  obs <- c(LowRef, HighRef, LowAlt, HighAlt)
  
  G <-
    2 * (rowSums(obs * log(
      matrix(obs, ncol = 4) / matrix(exp, ncol = 4)
    )))
  return(G)
}
#' @title getPvals_MH
#' @description Calculates/Returns pvalues
#' @param Gprime G Prime Statistic
#' @param deltaSNP Default is NULL
#' @param outlierFilter Choose outlier filtering method Either deltaSNP or Hampel 
#' @param filterThreshold Choose filter threshold value should be less than 0.5
#' @export 
getPvals_MH <-
  function(Gprime,
           deltaSNP = NULL,
           outlierFilter = c("deltaSNP", "Hampel"),
           filterThreshold)
  {
    
    if (outlierFilter == "deltaSNP") {
      
      if (abs(filterThreshold) >= 0.5) {
        stop("filterThreshold should be less than 0.5")
      }
      
      message("Using deltaSNP-index to filter outlier regions with a threshold of ", filterThreshold)
      trimGprime <- Gprime[abs(deltaSNP) < abs(filterThreshold)]
      #The next line is what I edited from the original getPvals
      trimGprime <- trimGprime[!is.na(trimGprime)]
    } else {
      message("Using Hampel's rule to filter outlier regions")
      lnGprime <- log(Gprime)
      
      medianLogGprime <- median(lnGprime)
      
      # calculate left median absolute deviation for the trimmed G' prime set
      MAD <-
        median(medianLogGprime - lnGprime[lnGprime <= medianLogGprime])
      
      # Trim the G prime set to exclude outlier regions (i.e. QTL) using Hampel's rule
      trimGprime <-
        Gprime[lnGprime - median(lnGprime) <= 5.2 * MAD]
    }
    
    medianTrimGprime <- median(trimGprime)
    
    # estimate the mode of the trimmed G' prime set using the half-sample method
    message("Estimating the mode of a trimmed G prime set using the 'modeest' package...")
    modeTrimGprime <-
      modeest::mlv(x = trimGprime, bw = 0.5, method = "hsm")[1]
    
    muE <- log(medianTrimGprime)
    varE <- abs(muE - log(modeTrimGprime))
    #use the log normal distribution to get pvals
    message("Calculating p-values...")
    pval <-
      1 - plnorm(q = Gprime,
                 meanlog = muE,
                 sdlog = sqrt(varE))
    
    return(pval)
  }

#' @title runQTLseqAnalysis_MH
#' @description Calculates/Returns SNPset 
#' @param  windowSize Specify Window Size
#' @param popStruc population Structure of the Segregant Bulks "F2" is default
#' @param bulkSize Choose appropriate parameters for bulk size in each BSA group 
#' @param depth Default is NULL
#' @param replications Choose the number of replications default is 10000
#' @param filter Choose specific filtering value default is 0.3
#' @param intervals Choose appropriate confidence intervals default is 95% - 99%
#' @export 



runQTLseqAnalysis_MH <- function (SNPset, windowSize = 1e+06, popStruc = "F2", bulkSize,
                                  depth = NULL, replications = 10000, filter = 0.3, intervals = c(95,
                                                                                                  99), ...)
{
  message("Counting SNPs in each window...")
  SNPset <- SNPset %>% dplyr::group_by(CHROM) %>% dplyr::mutate(nSNPs = countSNPs_cpp(POS = POS,
                                                                                      windowSize = windowSize))
  message("Calculating tricube smoothed delta SNP index...")
  SNPset <- SNPset %>% dplyr::mutate(tricubeDeltaSNP = tricubeStat(POS = POS,
                                                                   Stat = deltaSNP, windowSize))
  if (all(intervals >= 1)) {
    message("Returning the following two sided confidence intervals: ",
            paste(intervals, collapse = ", "))
    quantiles <- (100 - intervals)/200
  }
  else {
    stop("Convidence intervals ('intervals' paramater) should be supplied as two-sided percentiles. i.e. If intervals = '95' will return the two sided 95% confidence interval, 2.5% on each side.")
  }
  SNPset <- SNPset %>% drop_na()
  SNPset <- SNPset %>% dplyr::mutate(minDP = pmin(DP.LOW, DP.HIGH))
  SNPset <- SNPset %>% dplyr::group_by(CHROM) %>% dplyr::mutate(tricubeDP = floor(tricubeStat(POS,
                                                                                              minDP, windowSize = windowSize)))
  if (is.null(depth)) {
    message("Variable 'depth' not defined, using min and max depth from data: ",
            min(SNPset$minDP), "-", max(SNPset$minDP))
    depth <- min(SNPset$minDP):max(SNPset$minDP)
  }
  CI <- simulateConfInt(popStruc = popStruc, bulkSize = bulkSize,
                        depth = depth, replications = replications, filter = filter,
                        intervals = quantiles)
  names(CI)[1] <- "tricubeDP"
  SNPset <- dplyr::left_join(x = SNPset, y = CI)
  as.data.frame(SNPset)
}

#' @title Obs_Allele_Freq
#' @description Returns a 4 column data frame with Chromosome, Position, and Observed allele frequencies from the High Parent for both bulks
#' @param  SNPSet A SNPSet generated from the function importFromTable 
#' @export 


Obs_Allele_Freq <- function(SNPSet){
  frame <- SNPSet %>% dplyr::mutate(LowRef = AD_REF.LOW, HighRef = AD_REF.HIGH, LowAlt = AD_ALT.LOW, HighAlt = AD_ALT.HIGH) %>% select(LowRef, HighRef, LowAlt, HighAlt)
  p1 <- ((frame$LowAlt)/(frame$LowRef + frame$LowAlt))
  p2 <- ((frame$HighAlt)/(frame$HighRef + frame$HighAlt))
  Chrom <- SNPSet %>% select(CHROM)
  POS <- SNPSet %>% select(POS)
  POS <- as.character(POS)
  data <- cbind(Chrom,POS,p1,p2)
  data <- as.data.frame(data)
  e <- ggplot(data = data, aes(x = seq(1, length(p1),1), y = p1)) + geom_point(aes(color=factor(CHROM)))  + theme_bw()  + labs(x = "SNP", y = "Allele Frequency", title = "Low Bulk Observed High Parent Allele Frequency") 
  print(e)
  e1 <- ggplot(data = data, aes(x = seq(1, length(p2),1), y = p2)) + geom_point(aes(color=factor(CHROM))) + theme_bw() + labs(x = "SNP", y = "Allele Frequency",title = "High Bulk Observed High Parent Allele Frequency")
  print(e1) 
  return(data)
}



#' @title Obs_Allele_Freq2
#' @description Returns a 4 column data filtering for specific Chromosome and High Bulk Observed Allele Frequencies
#' @param SNPSet A SNPSet generated from the function importFromTable 
#' @param ChromosomeValue Input a Specific Chromosome Value
#' @param threshold Input a Specific Allele Frequency Threshold value from the High Bulk High Parent 
#' @export 



Obs_Allele_Freq2 <- function(SNPSet,ChromosomeValue,threshold){
  frame <- SNPSet %>% dplyr::mutate(LowRef = AD_REF.LOW, HighRef = AD_REF.HIGH, LowAlt = AD_ALT.LOW, HighAlt = AD_ALT.HIGH) %>% select(LowRef, HighRef, LowAlt, HighAlt)
  p1 <- ((frame$LowAlt)/(frame$LowRef + frame$LowAlt))
  p2 <- ((frame$HighAlt)/(frame$HighRef + frame$HighAlt))
  Chrom <- SNPSet %>% select(CHROM)
  POS <- SNPSet %>% select(POS)
  data <- cbind(Chrom,POS,p1,p2)
  data <- as.data.frame(data)
  data <- data[(as.matrix(data[1]) == ChromosomeValue),]
  data <- data[(as.matrix(data[4]) > threshold),]
  e <- ggplot(data = data, aes(x = seq(1, length(p1),1), y = p1)) + geom_point(aes(color=factor(CHROM))) + theme_bw()  + ggrepel::geom_label_repel(aes(label = as.character(POS))) + labs(x = "SNP", y = "Allele Frequency", title = "Low Bulk Observed High Parent Allele Frequency")
  print(e)
  e1 <- ggplot(data = data, aes(x = seq(1, length(p2),1), y = p2)) + geom_point(aes(color=factor(CHROM))) + ggrepel::geom_label_repel(aes(label = as.character(POS))) + theme_bw()   + labs(x = "SNP", y = "Allele Frequency", title = "High Bulk Observed High Parent Allele Frequency") 
  print(e1)
  return(data)
}

